# Neural Networks and Deep Learning
http://neuralnetworksanddeeplearning.com/  

# Backpropagation with Continuation Callbacks: Foundations for Efficient and Expressive Differentiable Programming
http://papers.nips.cc/paper/8221-backpropagation-with-callbacks-foundations-for-efficient-and-expressive-differentiable-programming.pdf  
https://www.scala-lang.org/api/2.9.2/scala/util/continuations/package.html  
https://www.scala-lang.org/old/node/2096  

# Lantern Shining a Light on Deep Learning
https://feiwang3311.github.io/Lantern/  

# GOVEC: SIMD SUPPORT FOR GOLANG
http://www.andrew.cmu.edu/user/sakshamj/15618/final.pdf  
https://github.com/sakjain92/govec  

# Optimizing Go programs by AVX2 using Auto-Vectorization in LLVM.
https://medium.com/@c_bata_/optimizing-go-by-avx2-using-auto-vectorization-in-llvm-118f7b366969  
https://github.com/stuartcarnie/go-simd  

# Quantum Computation Simulator written in golang
https://github.com/itsubaki/q  

# The Matrix Calculus You Need For Deep Learning
https://explained.ai/matrix-calculus/index.html  

# Loss Functions
https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#mae-l1  

# A list of cost functions used in neural networks, alongside applications
https://stats.stackexchange.com/questions/154879/a-list-of-cost-functions-used-in-neural-networks-alongside-applications  

# Loss Functions in Neural Networks
https://isaacchanghau.github.io/post/loss_functions/  

# From automatic differentiation to message passing
https://news.ycombinator.com/item?id=20687022  
https://www.youtube.com/watch?v=NkJNcEed2NU  

# Weld: Accelerating numpy, scikit and pandas as much as 100x with Rust and LLVM
https://news.ycombinator.com/item?id=21036503  
https://notamonadtutorial.com/weld-accelerating-numpy-scikit-and-pandas-as-much-as-100x-with-rust-and-llvm-12ec1c630a1  

